{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYEZUkSJLccNNDWEY+BF+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaswanthVIT/Vitamin_Detection/blob/main/Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing With PDF**"
      ],
      "metadata": {
        "id": "ZVfMKns_s8k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" -q\n",
        "# !pip install --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes xformers datasets -q\n",
        "# !pip install pdfplumber -q\n",
        "\n",
        "import unsloth\n",
        "print('Unsloth installed successfully')\n",
        "\n",
        "# 1. Mount Google Drive and load your model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your model directory path (update if needed)\n",
        "model_dir = \"/content/drive/MyDrive/pdf2bits_final_model\"\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model, _ = FastLanguageModel.from_pretrained(model_name=model_dir, max_seq_length=1024)\n",
        "\n",
        "# 2. Upload PDF\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "# 3. Extract text from PDF\n",
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "print(\"Extracted PDF text length:\", len(pdf_text))\n",
        "\n",
        "# 4. Semantic (sentence-based) chunking for summarization\n",
        "import re\n",
        "\n",
        "def simple_sentence_tokenize(text):\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "def semantic_chunk_text(text, max_words=150, min_words=50):\n",
        "    sentences = simple_sentence_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_length = len(sentence.split())\n",
        "        if current_length + sentence_length <= max_words:\n",
        "            current_chunk.append(sentence)\n",
        "            current_length += sentence_length\n",
        "        else:\n",
        "            if current_chunk and current_length >= min_words:\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "                current_chunk = [sentence]\n",
        "                current_length = sentence_length\n",
        "            else:\n",
        "                current_chunk.append(sentence)\n",
        "                current_length += sentence_length\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "chunks = semantic_chunk_text(pdf_text, max_words=150, min_words=50)\n",
        "print(f\"Total semantic chunks for summarization: {len(chunks)}\")\n",
        "\n",
        "# 5. Prompt template and post-processing workaround\n",
        "def make_prompt(chunk):\n",
        "    return (\n",
        "        \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\"\n",
        "        \"Generate a 10-word educational summary for this text:\\n\\n\"\n",
        "        f\"{chunk}\\n\"\n",
        "        \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
        "    )\n",
        "import re\n",
        "\n",
        "def extract_summary_from_output(output):\n",
        "    marker = \"Here is a 10-word educational summary for this text:\"\n",
        "    idx = output.find(marker)\n",
        "    if idx != -1:\n",
        "        # Get everything after the marker\n",
        "        after_marker = output[idx + len(marker):].strip()\n",
        "        # The summary is usually on the next non-empty line\n",
        "        for line in after_marker.split('\\n'):\n",
        "            clean_line = line.strip().strip('\"')\n",
        "            if clean_line:\n",
        "                # Optionally: limit to 10 words\n",
        "                return ' '.join(clean_line.split()[:10])\n",
        "    return \"\"\n",
        "\n",
        "summaries = []\n",
        "for chunk in chunks:\n",
        "    prompt = make_prompt(chunk)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=50, use_cache=True)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    summary = extract_summary_from_output(generated_text)\n",
        "    if summary:\n",
        "        summaries.append(summary)\n",
        "\n",
        "for s in summaries:\n",
        "    print(s)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "A-sD7wmjuN01",
        "outputId": "98837654-2c5b-4789-84cb-0a5ef565b151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Unsloth installed successfully\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "==((====))==  Unsloth 2025.6.12: Fast Llama patching. Transformers: 4.53.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e0b54bda-2219-4ead-a796-5bd7934ddac0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e0b54bda-2219-4ead-a796-5bd7934ddac0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1-Nature of Software Software Engineering Software process project product Process Models-14-12-2024-27-48.pdf to 1-Nature of Software Software Engineering Software process project product Process Models-14-12-2024-27-48.pdf\n",
            "Extracted PDF text length: 15347\n",
            "Total semantic chunks for summarization: 18\n",
            "Software Engineering: Application of Scientific and Practical Knowledge to Software\n",
            "Understand the problem before building a solution with modern complexity.\n",
            "Software engineering tools automate software development processes and improve efficiency.\n",
            "A software process framework sets the groundwork for software development.\n",
            "This helps understand project goals and requirements through planning and\n",
            "Developing a Food Delivery App Involves Planning and Testing Requirements\n",
            "Software Project Management: Planning, Tracking, and Controlling Software Development Activities\n",
            "Work Product Preparation and Production: Encompasses Work Product Management Processes\n",
            "Process flow describes different execution strategies for tasks and activities.\n",
            "The Waterfall Model is a systematic approach to software development.\n",
            "The Waterfall Model: A Step-by-Step Approach to Software Development\n",
            "Waterfall Methodology: A structured approach to software development and design.\n",
            "Team faces challenges when client requests change in software development.\n"
          ]
        }
      ]
    }
  ]
}